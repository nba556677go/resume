%====================
% EXPERIENCE A
%====================
\subsection{{Research Assistant \hfill 07.2023 --- Present}}
\subtext{\textbf{Stony Brook University, Advisor: \href{https://www3.cs.stonybrook.edu/~anshul/}{Dr.Anshul Gandhi}, \href{https://www.cs.stonybrook.edu/people/faculty/ZhenhuaLiu}{Dr.Zhenhua Liu}} \hfill Stony Brook, NY}

\begin{zitemize}
        \item \textbf{Project: GPU performance analysis and prediction on DL serving}
        \item Improved GPU utilization by predicting and minimizing job interference under colocation. Reduced 36\% completion time.
        \item Predicted optimal job colocation using fine-grained GPU kernel profiles from \textbf{NVIDIA Nsight Compute}. Analyzed over 20 GPU metrics to colocate workloads based on compute, memory, and cache usage.
        \item Trained a regression model with kernel metrics. Achieved 90\% prediction accuracy with 30\% of data as training set.
        \item Leveraged \textbf{NVIDIA MPS} for efficient job sharing with compute isolation. Achieved 1.5x increase in throughput.
\end{zitemize}
\vspace{-1.5pt}
\begin{zitemize}
        \item \textbf{Project: Optimize DL scheduling with Kubernetes}
        \item Optimized \textbf{AI systems} scheduling policies, enabling efficient resource allocation for colocating ML tasks like chatbot and document retrieval, resulting in a 20\% reduction in task completion time.
        \item Constructed an end-to-end ML deployment pipeline using \textbf{Kubernetes}. Modified K8S scheduler source
        code to enable \textbf{shortest-job-first} scheduling. Achieved a 20\% reduction in total completion time.
        \item Implemented an ML profiler for accurate prediction of GPU memory and time usage. Predicted task
completion time within 4\% error rate.
\end{zitemize}

%====================
% EXPERIENCE C
%====================
\subsection{{Data Engineer Intern \hfill 12.2018 --- 07.2019}}
\subtext{\textbf{Cathay Financial Holdings} \hfill Taipei, Taiwan}
\begin{zitemize}
        \item Developed scalable machine learning pipelines using \textbf{Hadoop}, \textbf{Spark}, and \textbf{Kafka} microservices, leveraging Docker to ensure efficient distributed computing for high-volume data processing.
        \item Deployed an \textbf{automation pipeline} for configuration tuning, reducing configuration time by 50\% in \textbf{Proof-of-Concepts}.
\end{zitemize}
%====================
% EXPERIENCE B
%====================
\subsection{{Technical sales Intern \hfill 04.2021 --- 04.2022}}
\subtext{\textbf{Intel} \hfill Taipei, Taiwan}
\begin{zitemize}
\item Led \textbf{Xeon E server launch program} in Asia (\$300M data center business). Strengthened cross-geographical \textbf{market relations} and engaged with 20+ \textbf{ODM supply manufacturers} to resolve platform enablement challenges.
\end{zitemize}



%====================
% EXPERIENCE D
%====================
%\subsection{{ROLE / PROJECT D \hfill MMM YYYY --- MMM YYYY}}
%\subtext{company D \hfill somewhere, state}
%\begin{zitemize}
%\item Vestibulum accumsan massa quis dignissim faucibus.
%\item Maecenas suscipit mi ut ullamcorper pharetra.
%\item In vitae ligula tristique, iaculis tortor in, egestas magna.
%\item In fringilla purus malesuada lectus imperdiet pulvinar.
%\item Nulla eu dolor congue, mollis dui a, eleifend purus.
%\end{zitemize}

%====================
% EXPERIENCE E
%====================
%\subsection{{ROLE / PROJECT E \hfill MMM YYYY --- MMM YYYY}}
%\subtext{company E \hfill somewhere, state}
%\begin{zitemize}
%\item In lobortis libero consectetur eros vehicula, vel pellentesque quam fringilla.
%\item Ut malesuada purus at mi placerat dapibus.
%\item Suspendisse finibus massa eu nisi dictum, a imperdiet tellus convallis.
%\item Nam feugiat erat vestibulum lacus feugiat, efficitur gravida nunc imperdiet.
%\item Morbi porta lacus vitae augue luctus, a rhoncus est sagittis.
%\end{zitemize}
